"""
å†…å®¹å¤„ç†è¾…åŠ©æ¨¡å—
æä¾›å›¾ç‰‡å¤„ç†ã€æ–‡æœ¬åˆå¹¶ã€å›¾ç‰‡åˆ†ç»„ç­‰è¾…åŠ©åŠŸèƒ½
"""

import shutil
import re
from pathlib import Path
from PIL import Image
from typing import Dict, List


def process_images(
    content_list: list,
    extract_dir: str,
    output_paths: dict,
    logger,
    config: dict
) -> int:
    """
    å¤„ç†å›¾ç‰‡ï¼šå¤åˆ¶å›¾ç‰‡åˆ°HTMLè¾“å‡ºç›®å½•å¹¶æ›´æ–°è·¯å¾„

    Args:
        content_list: å†…å®¹åˆ—è¡¨
        extract_dir: MinerUè§£å‹ç›®å½•
        output_paths: è¾“å‡ºè·¯å¾„å­—å…¸
        logger: æ—¥å¿—è®°å½•å™¨
        config: é…ç½®å­—å…¸

    Returns:
        å¤åˆ¶çš„å›¾ç‰‡æ•°é‡
    """
    extract_dir = Path(extract_dir)
    source_images_dir = extract_dir / "images"

    if not source_images_dir.exists():
        logger.warning(f"æœªæ‰¾åˆ°å›¾ç‰‡ç›®å½•: {source_images_dir}")
        return 0

    # ç¡®å®šç›®æ ‡å›¾ç‰‡ç›®å½•ï¼ˆç»Ÿä¸€æ”¾åœ¨ output/HTML/images/ï¼‰
    output_base = Path(config['paths']['output_base'])
    html_folder = config['output']['html_folder']
    html_base_dir = output_base / html_folder

    if output_paths and 'html_original' in output_paths:
        # ä½¿ç”¨ä¸ HTML æ–‡ä»¶ç›¸åŒçš„ç›®å½•å±‚çº§
        html_dir = Path(output_paths['html_original']).parent
    else:
        html_dir = html_base_dir

    target_images_dir = html_dir / "images"
    target_images_dir.mkdir(parents=True, exist_ok=True)

    logger.info(f"æ­£åœ¨å¤åˆ¶å›¾ç‰‡: {source_images_dir} -> {target_images_dir}")

    # å¤åˆ¶å›¾ç‰‡å¹¶æ›´æ–°è·¯å¾„ï¼ˆåŒ…æ‹¬æ™®é€šå›¾ç‰‡å’Œè¡¨æ ¼å›¾ç‰‡ï¼‰
    copied_count = 0
    for item in content_list:
        # ä¿®å¤ï¼šåŒæ—¶å¤„ç† type=='image' å’Œ type=='table' çš„å›¾ç‰‡
        if item.get('img_path') and item.get('type') in ['image', 'table']:
            img_rel_path = item['img_path']
            source_img = extract_dir / img_rel_path

            if source_img.exists():
                img_filename = Path(img_rel_path).name
                target_img = target_images_dir / img_filename

                # å¤åˆ¶å›¾ç‰‡
                shutil.copy2(source_img, target_img)

                # è¯»å–å›¾ç‰‡å°ºå¯¸å¹¶è®¡ç®—å®½é«˜æ¯”
                try:
                    with Image.open(target_img) as img:
                        width, height = img.size
                        aspect_ratio = width / height if height > 0 else 1.0
                        item['img_width'] = width
                        item['img_height'] = height
                        item['img_aspect_ratio'] = aspect_ratio

                        # åˆ¤æ–­å›¾ç‰‡ç±»å‹ï¼šçª„é•¿å›¾(å®½é«˜æ¯”<0.6)ã€æ­£å¸¸å›¾ã€æ‰å¹³å›¾(å®½é«˜æ¯”>1.8)
                        if aspect_ratio < 0.6:
                            item['img_layout_type'] = 'narrow'  # çª„é•¿å›¾
                        elif aspect_ratio > 1.8:
                            item['img_layout_type'] = 'wide'  # æ‰å¹³å›¾
                        else:
                            item['img_layout_type'] = 'normal'  # æ­£å¸¸å›¾
                except Exception as e:
                    logger.warning(f"æ— æ³•è¯»å–å›¾ç‰‡å°ºå¯¸ {img_filename}: {str(e)}")
                    item['img_layout_type'] = 'normal'

                # æ›´æ–°è·¯å¾„ï¼š
                # 1. ç›¸å¯¹è·¯å¾„ç”¨äº HTMLï¼ˆimages/xxx.jpgï¼‰
                # 2. ç»å¯¹è·¯å¾„ç”¨äº PDF/DOCX è½¬æ¢ï¼ˆå­˜å‚¨åœ¨ img_path_absoluteï¼‰
                item['img_path'] = f"images/{img_filename}"
                # ä¿®å¤ï¼šWindowsè·¯å¾„è½¬æ¢ä¸ºfile://åè®®æ ¼å¼
                abs_path = target_img.absolute().as_posix()  # ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ 
                item['img_path_absolute'] = abs_path  # ä¸åŠ file:///å‰ç¼€ï¼Œæ¨¡æ¿ä¸­å¤„ç†
                copied_count += 1
            else:
                logger.warning(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {source_img}")

    if copied_count > 0:
        logger.success(f"å·²å¤åˆ¶ {copied_count} å¼ å›¾ç‰‡")
    else:
        logger.warning("æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶")

    return copied_count


def merge_split_texts(items: list) -> list:
    """
    æç®€åˆå¹¶ - åªå¤„ç†æ˜ç¡®çš„TEXTåˆ†å‰²

    è§„åˆ™1: è¿å­—ç¬¦æ–­è¯ (å¦‚ "frig-" + "ates")
    è§„åˆ™2: è·¨åˆ—æ— æ ‡ç‚¹ (å¦‚å·¦åˆ— "...limestone" + å³åˆ— "V pedestal")
    è§„åˆ™3: åŒåˆ—åˆ†å‰² (å¦‚ "...Pound" + "force was...")

    Args:
        items: å•é¡µçš„å†…å®¹é¡¹åˆ—è¡¨

    Returns:
        åˆå¹¶åçš„å†…å®¹é¡¹åˆ—è¡¨ï¼ˆä¿ç•™original_itemså­—æ®µï¼‰
    """
    merged = []
    i = 0

    while i < len(items):
        current = items[i]

        # åªå¤„ç†textç±»å‹
        if current.get('type') != 'text' or not current.get('text'):
            merged.append(current)
            i += 1
            continue

        # æ£€æŸ¥æ˜¯å¦ä¸ä¸‹ä¸€é¡¹åˆå¹¶
        should_merge = False
        if i + 1 < len(items):
            next_item = items[i + 1]

            # ä¸‹ä¸€é¡¹ä¹Ÿå¿…é¡»æ˜¯text
            if next_item.get('type') == 'text' and next_item.get('text'):
                # åŒä¸€é¡µ
                if current.get('page_idx') == next_item.get('page_idx'):
                    text1 = current['text'].strip()
                    bbox1 = current.get('bbox', [0, 0, 0, 0])
                    bbox2 = next_item.get('bbox', [0, 0, 0, 0])

                    # è§„åˆ™1: è¿å­—ç¬¦ç»“å°¾ (100%ç¡®å®šæ˜¯æ–­è¯)
                    if text1.endswith('-'):
                        should_merge = True
                    # è§„åˆ™2: è·¨åˆ— + æ— å¥æœ«æ ‡ç‚¹
                    elif bbox2[0] - bbox1[2] > 80:  # xé—´è· > 80åƒç´ ï¼ˆè·¨åˆ—ï¼‰
                        if text1 and text1[-1] not in '.!?ã€‚ï¼ï¼Ÿ':
                            should_merge = True
                    # è§„åˆ™3: åŒåˆ—å†…åˆ†å‰² - text1æ— æ ‡ç‚¹ç»“å°¾ + text2å°å†™å¼€å¤´
                    else:
                        text2 = next_item['text'].strip()
                        # text1ä¸ä»¥æ ‡ç‚¹ç»“å°¾ ä¸” text2ä»¥å°å†™å­—æ¯å¼€å¤´
                        if (text1 and text1[-1] not in '.!?ã€‚ï¼ï¼Ÿ,;:' and
                            text2 and text2[0].islower()):
                            should_merge = True

        if should_merge:
            # åˆå¹¶ä¸¤ä¸ªTEXTå—
            merged_item = current.copy()
            merged_item['text'] = current['text'].rstrip() + ' ' + next_item['text'].lstrip()
            merged_item['original_items'] = [current, next_item]
            merged_item['merged'] = True
            merged.append(merged_item)
            i += 2  # è·³è¿‡ä¸‹ä¸€é¡¹
        else:
            merged.append(current)
            i += 1

    return merged


def group_narrow_images(pages: dict, logger) -> dict:
    """
    å¯¹è¿ç»­çš„çª„é•¿å›¾ç‰‡è¿›è¡Œåˆ†ç»„ï¼Œä½¿å…¶å¹¶æ’æ˜¾ç¤º

    Args:
        pages: {page_idx: [items]} é¡µé¢å†…å®¹å­—å…¸
        logger: æ—¥å¿—è®°å½•å™¨

    Returns:
        å¤„ç†åçš„pageså­—å…¸
    """
    total_groups = 0
    total_narrow_images = 0

    for page_idx, items in pages.items():
        grouped_items = []
        i = 0

        while i < len(items):
            item = items[i]

            # å¦‚æœæ˜¯çª„é•¿å›¾ç‰‡ï¼Œå°è¯•æ‰¾åˆ°è¿ç»­çš„çª„é•¿å›¾ç‰‡
            if item.get('type') == 'image' and item.get('img_layout_type') == 'narrow':
                # æ”¶é›†è¿ç»­çš„çª„é•¿å›¾ç‰‡
                narrow_group = [item]
                j = i + 1

                # æœ€å¤šåˆå¹¶4å¼ çª„é•¿å›¾ç‰‡åˆ°ä¸€è¡Œ
                while j < len(items) and len(narrow_group) < 4:
                    next_item = items[j]
                    # æ£€æŸ¥ä¸‹ä¸€é¡¹æ˜¯å¦ä¹Ÿæ˜¯çª„é•¿å›¾ç‰‡
                    if next_item.get('type') == 'image' and next_item.get('img_layout_type') == 'narrow':
                        narrow_group.append(next_item)
                        j += 1
                    else:
                        break

                # å¦‚æœæœ‰2å¼ åŠä»¥ä¸Šçª„é•¿å›¾ç‰‡ï¼Œåˆ›å»ºå›¾ç‰‡ç»„
                if len(narrow_group) >= 2:
                    grouped_items.append({
                        'type': 'image_group',
                        'layout_type': 'narrow_row',  # çª„é•¿å›¾ç‰‡æ¨ªæ’
                        'images': narrow_group,
                        'page_idx': item.get('page_idx')
                    })
                    total_groups += 1
                    total_narrow_images += len(narrow_group)
                    i = j  # è·³è¿‡å·²å¤„ç†çš„å›¾ç‰‡
                else:
                    # åªæœ‰1å¼ çª„é•¿å›¾ç‰‡ï¼Œæ­£å¸¸å¤„ç†
                    grouped_items.append(item)
                    i += 1
            else:
                # éçª„é•¿å›¾ç‰‡ï¼Œæ­£å¸¸æ·»åŠ 
                grouped_items.append(item)
                i += 1

        # æ›´æ–°é¡µé¢å†…å®¹
        pages[page_idx] = grouped_items

    if total_groups > 0:
        logger.info(f"ğŸ“ å›¾ç‰‡æ™ºèƒ½æ’ç‰ˆ: åˆ›å»ºäº† {total_groups} ä¸ªå›¾ç‰‡ç»„ï¼ŒåŒ…å« {total_narrow_images} å¼ çª„é•¿å›¾ç‰‡")

    return pages


def get_chapter_context(page_idx: int, outline: dict) -> dict:
    """
    è·å–é¡µé¢å¯¹åº”çš„ç« èŠ‚ä¸Šä¸‹æ–‡

    Args:
        page_idx: é¡µç 
        outline: æ–‡æ¡£å¤§çº²

    Returns:
        åŒ…å«ç« èŠ‚æ ‡é¢˜ã€æ‘˜è¦ã€å…³é”®è¯çš„å­—å…¸
    """
    # åŸºç¡€ä¸Šä¸‹æ–‡ï¼šåŒ…å«æ–‡æ¡£çº§åˆ«çš„æœŸåˆŠæ¦‚è¿°
    context = {
        'journal_overview': outline.get('journal_overview', '')
    }

    # ç¡®ä¿ page_idx æ˜¯æ•´æ•°
    try:
        page_num = int(page_idx)
    except (ValueError, TypeError):
        return context

    # æŸ¥æ‰¾å¯¹åº”çš„ç« èŠ‚ä¿¡æ¯
    for chapter in outline.get('structure', []):
        pages = chapter.get('pages', [])
        if len(pages) >= 2:
            try:
                # ç¡®ä¿ start å’Œ end ä¹Ÿæ˜¯æ•´æ•°
                start = int(pages[0])
                end = int(pages[1])
                if start <= page_num <= end:
                    context.update({
                        'chapter_title': chapter.get('title', ''),
                        'chapter_summary': chapter.get('summary', ''),
                        'keywords': chapter.get('keywords', [])
                    })
                    return context
            except (ValueError, TypeError, IndexError):
                continue

    return context
