"""
ç¿»è¯‘ä»»åŠ¡ç®¡ç†æ¨¡å—
è´Ÿè´£æ”¶é›†ç¿»è¯‘ä»»åŠ¡ã€æ‰§è¡Œæ‰¹é‡ç¿»è¯‘ã€åˆ†é…ç»“æœå’Œç®¡ç†å¤±è´¥æ–‡æœ¬é‡è¯•
"""

import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from article_translator import ArticleTranslator


class TranslationTaskManager:
    """ç¿»è¯‘ä»»åŠ¡ç®¡ç†å™¨ - æ”¶é›†ä»»åŠ¡ã€æ‰§è¡Œç¿»è¯‘ã€åˆ†é…ç»“æœ"""

    def __init__(self, logger, config):
        """
        åˆå§‹åŒ–ç¿»è¯‘ä»»åŠ¡ç®¡ç†å™¨

        Args:
            logger: æ—¥å¿—è®°å½•å™¨
            config: é…ç½®å­—å…¸
        """
        self.logger = logger
        self.config = config
        self.failed_texts_log = Path("logs/total_issue_files.jsonl")

    def is_garbage_text(self, text: str) -> bool:
        """
        æ£€æµ‹æ–‡æœ¬æ˜¯å¦ä¸ºOCRè¯†åˆ«é”™è¯¯äº§ç”Ÿçš„ä¹±ç ï¼ˆæ§åˆ¶å­—ç¬¦åƒåœ¾æ–‡æœ¬ï¼‰

        Args:
            text: å¾…æ£€æµ‹æ–‡æœ¬

        Returns:
            Trueè¡¨ç¤ºæ˜¯åƒåœ¾æ–‡æœ¬ï¼ŒFalseè¡¨ç¤ºæ­£å¸¸æ–‡æœ¬
        """
        if not text or len(text) < 10:
            return False

        # ç»Ÿè®¡æ§åˆ¶å­—ç¬¦æ•°é‡ï¼ˆæ’é™¤å¸¸è§çš„æ¢è¡Œã€åˆ¶è¡¨ç¬¦ï¼‰
        control_chars = sum(1 for c in text if ord(c) < 32 and c not in '\n\t\r')

        # å¦‚æœæ§åˆ¶å­—ç¬¦å æ¯”è¶…è¿‡80%ï¼Œè®¤ä¸ºæ˜¯åƒåœ¾æ–‡æœ¬ï¼ˆæ›´ä¿å®ˆçš„é˜ˆå€¼ï¼‰
        return control_chars / len(text) > 0.8

    def load_failed_cache(self) -> Dict:
        """
        åŠ è½½å¤±è´¥æ–‡æœ¬ç¼“å­˜

        Returns:
            å¤±è´¥æ–‡æœ¬ç¼“å­˜å­—å…¸ {text_id: record}
        """
        failed_texts_cache = {}
        if self.failed_texts_log.exists():
            self.logger.info("æ£€æµ‹åˆ°å¤±è´¥æ–‡æœ¬æ—¥å¿—ï¼Œæ­£åœ¨åŠ è½½...")
            try:
                with open(self.failed_texts_log, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            record = json.loads(line)
                            text_id = record.get('text_id')
                            if text_id:
                                failed_texts_cache[text_id] = record
                self.logger.info(f"å·²åŠ è½½ {len(failed_texts_cache)} æ¡å¤±è´¥è®°å½•")
            except Exception as e:
                self.logger.warning(f"è¯»å–å¤±è´¥æ—¥å¿—å‡ºé”™: {str(e)}")
        return failed_texts_cache

    def collect_tasks(
        self,
        pages: dict,
        outline: dict,
        get_chapter_context_func
    ) -> List[Tuple]:
        """
        æ”¶é›†æ‰€æœ‰éœ€è¦ç¿»è¯‘çš„ä»»åŠ¡

        Args:
            pages: {page_idx: [items]} é¡µé¢å†…å®¹å­—å…¸
            outline: æ–‡æ¡£å¤§çº²
            get_chapter_context_func: è·å–ç« èŠ‚ä¸Šä¸‹æ–‡çš„å‡½æ•°

        Returns:
            [(item, field_name, text, context), ...] ä»»åŠ¡åˆ—è¡¨
        """
        tasks = []

        for page_idx in sorted(pages.keys()):
            items = pages[page_idx]

            # è·å–ç« èŠ‚ä¸Šä¸‹æ–‡
            chapter_context = get_chapter_context_func(page_idx, outline)

            for idx, item in enumerate(items):
                # æ£€æŸ¥itemæ˜¯å¦æœ‰typeå­—æ®µï¼Œå¦‚æœæ²¡æœ‰åˆ™è·³è¿‡
                item_type = item.get('type')
                if not item_type:
                    # æ²¡æœ‰typeå­—æ®µï¼Œæ ‡è®°ä¸ºå·²å¤„ç†å¹¶è·³è¿‡
                    item['processed'] = True
                    continue

                # åªè·³è¿‡çœŸæ­£ä¸éœ€è¦ç¿»è¯‘çš„å†…å®¹
                if item_type in ['footer', 'page_number']:
                    continue

                # æ·»åŠ ä¸Šä¸‹æ–‡çª—å£ï¼ˆå‰å500å­—ç¬¦ï¼Œæä¾›æ›´å……è¶³çš„ä¸Šä¸‹æ–‡å‚è€ƒï¼‰
                context = chapter_context.copy()
                if idx > 0 and items[idx - 1].get('text'):
                    context['prev_text'] = items[idx - 1]['text'][-500:]
                else:
                    context['prev_text'] = ''

                if idx < len(items) - 1 and items[idx + 1].get('text'):
                    context['next_text'] = items[idx + 1]['text'][:500]
                else:
                    context['next_text'] = ''

                # 1. æ­£æ–‡æ–‡æœ¬
                if item_type == 'text' and item.get('text'):
                    # è¿‡æ»¤OCRåƒåœ¾æ–‡æœ¬ï¼ˆæ§åˆ¶å­—ç¬¦ä¹±ç ï¼‰
                    if self.is_garbage_text(item['text']):
                        item['processed'] = True  # æ ‡è®°ä¸ºå·²å¤„ç†ï¼Œè·³è¿‡ç¿»è¯‘
                        continue
                    tasks.append((item, 'text_zh', item['text'], context))

                # 2. é¡µé¢è„šæ³¨ï¼ˆé‡è¦æ³¨é‡Šï¼‰
                if item_type == 'page_footnote' and item.get('text'):
                    # è¿‡æ»¤OCRåƒåœ¾æ–‡æœ¬ï¼ˆæ§åˆ¶å­—ç¬¦ä¹±ç ï¼‰
                    if self.is_garbage_text(item['text']):
                        item['processed'] = True  # æ ‡è®°ä¸ºå·²å¤„ç†ï¼Œè·³è¿‡ç¿»è¯‘
                        continue
                    tasks.append((item, 'text_zh', item['text'], context))

                # 3. åˆ—è¡¨é¡¹
                if item_type == 'list' and item.get('list_items'):
                    # åˆå§‹åŒ–åˆ—è¡¨ç¿»è¯‘å­—æ®µ
                    if 'list_items_zh' not in item:
                        item['list_items_zh'] = []
                    # ç¿»è¯‘æ¯ä¸ªåˆ—è¡¨é¡¹
                    for list_item in item['list_items']:
                        if list_item and isinstance(list_item, str):
                            # è¿‡æ»¤OCRåƒåœ¾æ–‡æœ¬
                            if not self.is_garbage_text(list_item):
                                tasks.append((item, 'list_items_zh', list_item, context))

                # 4. è¡¨æ ¼
                if item_type == 'table':
                    # ç¿»è¯‘è¡¨æ ¼æ ‡é¢˜
                    if item.get('table_caption'):
                        caption_text = ' '.join(item['table_caption']) if isinstance(item['table_caption'], list) else item['table_caption']
                        # è¿‡æ»¤OCRåƒåœ¾æ–‡æœ¬
                        if not self.is_garbage_text(caption_text):
                            tasks.append((item, 'table_caption_zh', caption_text, context))
                    # ç¿»è¯‘è¡¨æ ¼å†…å®¹
                    if item.get('table_body'):
                        tasks.append((item, 'table_body_zh', item['table_body'], context))

                # 5. å›¾ç‰‡
                if item_type == 'image':
                    # ç¿»è¯‘å›¾ç‰‡æ ‡é¢˜
                    if item.get('image_caption'):
                        caption_text = ' '.join(item['image_caption']) if isinstance(item['image_caption'], list) else item['image_caption']
                        # è¿‡æ»¤OCRåƒåœ¾æ–‡æœ¬
                        if not self.is_garbage_text(caption_text):
                            tasks.append((item, 'image_caption_zh', caption_text, context))
                    # ç¿»è¯‘å›¾ç‰‡è„šæ³¨
                    if item.get('image_footnote'):
                        footnote_text = ' '.join(item['image_footnote']) if isinstance(item['image_footnote'], list) else item['image_footnote']
                        if footnote_text:
                            # è¿‡æ»¤OCRåƒåœ¾æ–‡æœ¬
                            if not self.is_garbage_text(footnote_text):
                                tasks.append((item, 'image_footnote_zh', footnote_text, context))

                # 6. å‚è€ƒæ–‡çŒ®ï¼ˆä¸ç¿»è¯‘ï¼Œä½†æ ‡è®°ä¸ºå·²å¤„ç†ï¼‰
                if item_type == 'ref_text':
                    item['processed'] = True

                # 7. ä»£ç å—ï¼ˆä¸ç¿»è¯‘ï¼Œä½†æ ‡è®°ä¸ºå·²å¤„ç†ï¼‰
                if item_type == 'code':
                    item['processed'] = True

        return tasks

    def execute_translations(
        self,
        tasks: List[Tuple],
        translator: ArticleTranslator
    ) -> List[str]:
        """
        æ‰¹é‡æ‰§è¡Œç¿»è¯‘ï¼ˆå¸¦ text_id è¿½è¸ªï¼‰

        Args:
            tasks: [(item, field_name, text, context), ...] ä»»åŠ¡åˆ—è¡¨
            translator: ç¿»è¯‘å™¨å®ä¾‹

        Returns:
            ç¿»è¯‘ç»“æœåˆ—è¡¨
        """
        self.logger.info(f"å…±æ”¶é›† {len(tasks)} ä¸ªç¿»è¯‘ä»»åŠ¡ï¼Œå¼€å§‹å¹¶å‘ç¿»è¯‘...")

        # æ‰¹é‡å¹¶å‘ç¿»è¯‘ï¼ˆå¸¦text_idè¿½è¸ªï¼‰
        translation_tasks = []
        for task_idx, (item, field_name, text, context) in enumerate(tasks):
            # ç”Ÿæˆå”¯ä¸€çš„text_id
            page_idx = item.get('page_idx', 0)
            text_id = f"page_{page_idx}_task_{task_idx}_{field_name}"

            # å°†text_idæ·»åŠ åˆ°contextä¸­
            context_with_id = context.copy()
            context_with_id['text_id'] = text_id
            context_with_id['page_idx'] = page_idx

            translation_tasks.append((text, context_with_id))

        translations = translator.translate_batch(translation_tasks)
        return translations

    def assign_results(
        self,
        tasks: List[Tuple],
        translations: List[str],
        failed_texts_cache: Dict
    ) -> Dict:
        """
        å°†ç¿»è¯‘ç»“æœåˆ†é…å›åŸå§‹ items

        Args:
            tasks: [(item, field_name, text, context), ...] ä»»åŠ¡åˆ—è¡¨
            translations: ç¿»è¯‘ç»“æœåˆ—è¡¨
            failed_texts_cache: å¤±è´¥æ–‡æœ¬ç¼“å­˜

        Returns:
            é‡è¯•ç»Ÿè®¡ä¿¡æ¯ {'retry_success_count': int, 'retry_failed_count': int}
        """
        # è·Ÿè¸ªå“ªäº›ä¹‹å‰å¤±è´¥çš„æ–‡æœ¬è¿™æ¬¡æˆåŠŸäº†
        retry_success_count = 0
        retry_failed_count = 0

        # èµ‹å€¼ç¿»è¯‘ç»“æœ
        for i, (item, field_name, original_text, context) in enumerate(tasks):
            translated_text = translations[i]

            # ç”Ÿæˆ text_idï¼ˆéœ€è¦ä¸ execute_translations ä¸­çš„é€»è¾‘ä¸€è‡´ï¼‰
            page_idx = item.get('page_idx', 0)
            text_id = f"page_{page_idx}_task_{i}_{field_name}"

            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¹‹å‰å¤±è´¥çš„æ–‡æœ¬
            if text_id in failed_texts_cache:
                # æ£€æŸ¥è¿™æ¬¡æ˜¯å¦ç¿»è¯‘æˆåŠŸï¼ˆè¯‘æ–‡ä¸ç­‰äºåŸæ–‡ï¼‰
                if translated_text != original_text:
                    retry_success_count += 1
                    # ä»ç¼“å­˜ä¸­ç§»é™¤ï¼ˆè¡¨ç¤ºå·²æˆåŠŸï¼‰
                    del failed_texts_cache[text_id]
                else:
                    retry_failed_count += 1

            # æ£€æŸ¥æ˜¯å¦æ˜¯åˆå¹¶é¡¹
            if item.get('merged') and 'original_items' in item:
                # æ‹†åˆ†è¯‘æ–‡å›åŸå§‹TEXTå—
                originals = item['original_items']

                # æŒ‰åŸå§‹æ–‡æœ¬é•¿åº¦æ¯”ä¾‹æ‹†åˆ†
                len1 = len(originals[0]['text'])
                len2 = len(originals[1]['text'])
                total_len = len1 + len2

                if total_len > 0:
                    ratio = len1 / total_len
                    split_point = int(len(translated_text) * ratio)

                    # åˆ†é…è¯‘æ–‡
                    originals[0][field_name] = translated_text[:split_point].strip()
                    originals[1][field_name] = translated_text[split_point:].strip()

                    # ä¿ç•™åˆå¹¶ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                    originals[0]['_merged_from'] = item['text']
                    originals[1]['_merged_from'] = item['text']
                else:
                    # å¼‚å¸¸æƒ…å†µï¼šåŸå§‹æ–‡æœ¬é•¿åº¦ä¸º0ï¼Œç›´æ¥èµ‹å€¼ç»™ç¬¬ä¸€ä¸ª
                    originals[0][field_name] = translated_text
            else:
                # ç‰¹æ®Šå¤„ç†ï¼šåˆ—è¡¨é¡¹éœ€è¦appendè€Œä¸æ˜¯èµ‹å€¼
                if field_name == 'list_items_zh':
                    if 'list_items_zh' not in item:
                        item['list_items_zh'] = []
                    item['list_items_zh'].append(translated_text)
                else:
                    # å…¶ä»–å­—æ®µç›´æ¥èµ‹å€¼
                    item[field_name] = translated_text

            if (i + 1) % max(1, len(tasks) // 10) == 0:
                progress = (i + 1) * 100 // len(tasks)
                self.logger.info(f"  ç¿»è¯‘è¿›åº¦: {i + 1}/{len(tasks)} ({progress}%)")

        self.logger.success(f"ç¿»è¯‘å®Œæˆ: {len(tasks)} ä¸ªå†…å®¹å—")

        return {
            'retry_success_count': retry_success_count,
            'retry_failed_count': retry_failed_count
        }

    def update_failed_log(
        self,
        failed_texts_cache: Dict,
        retry_stats: Dict
    ) -> None:
        """
        æ›´æ–°å¤±è´¥æ—¥å¿—æ–‡ä»¶

        Args:
            failed_texts_cache: å¤±è´¥æ–‡æœ¬ç¼“å­˜
            retry_stats: é‡è¯•ç»Ÿè®¡ä¿¡æ¯
        """
        retry_success_count = retry_stats['retry_success_count']
        retry_failed_count = retry_stats['retry_failed_count']

        # è¾“å‡ºé‡è¯•ç»Ÿè®¡
        if retry_success_count > 0 or retry_failed_count > 0:
            self.logger.info(f"\nğŸ“Š å¤±è´¥æ–‡æœ¬é‡è¯•ç»Ÿè®¡:")
            if retry_success_count > 0:
                self.logger.success(f"  âœ“ é‡è¯•æˆåŠŸ: {retry_success_count} ä¸ª")
            if retry_failed_count > 0:
                self.logger.warning(f"  âœ— ä»å¤±è´¥: {retry_failed_count} ä¸ª")

        # æ›´æ–°å¤±è´¥æ—¥å¿—ï¼ˆç§»é™¤æˆåŠŸçš„è®°å½•ï¼‰
        if self.failed_texts_log.exists() and retry_success_count > 0:
            try:
                # è¯»å–æ‰€æœ‰è®°å½•
                all_records = []
                with open(self.failed_texts_log, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            record = json.loads(line)
                            # åªä¿ç•™ä»å¤±è´¥çš„è®°å½•
                            if record.get('text_id') in failed_texts_cache:
                                all_records.append(record)

                # é‡å†™æ–‡ä»¶
                with open(self.failed_texts_log, 'w', encoding='utf-8') as f:
                    for record in all_records:
                        f.write(json.dumps(record, ensure_ascii=False) + '\n')

                self.logger.success(f"å·²æ›´æ–°å¤±è´¥æ—¥å¿—ï¼Œç§»é™¤ {retry_success_count} æ¡æˆåŠŸè®°å½•")

            except Exception as e:
                self.logger.warning(f"æ›´æ–°å¤±è´¥æ—¥å¿—å‡ºé”™: {str(e)}")
